{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrlzvPNHuEi4xmuVkDQHld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52430/explainable-AI-LAB/blob/main/x_ai_ass_2_2430.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ==============================\n",
        " # SHAP Assignment - Retail & E-commerce\n",
        " # Dataset: Online Shoppers Purchasing Intention (UCI)\n",
        " # ==============================\n",
        " # Install if missing:\n",
        " # pip install pandas numpy scikit-learn shap matplotlib seaborn\n",
        " import pandas as pd\n",
        " import numpy as np\n",
        " import matplotlib.pyplot as plt\n",
        " import shap\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        " from sklearn.compose import ColumnTransformer\n",
        " from sklearn.pipeline import Pipeline\n",
        " from sklearn.ensemble import RandomForestClassifier\n",
        " from sklearn.metrics import (\n",
        " accuracy_score, precision_score, recall_score,\n",
        " f1_score, roc_auc_score, confusion_matrix\n",
        " )\n",
        " # ------------------------\n",
        "# Load Dataset\n",
        " # ------------------------\n",
        "df = pd.read_csv(\"\")\n",
        " print(\"Shape:\", df.shape)\n",
        " print(df.head())\n",
        " # ------------------------\n",
        "# Preprocessing\n",
        " # ------------------------\n",
        "target = \"Revenue\"\n",
        " df[target] = df[target].astype(int) # Convert to int\n",
        " df = df.drop_duplicates() # Drop duplicates\n",
        " print(\"Missing values:\\n\", df.isnull().sum())\n",
        " # Identify categorical & numeric columns\n",
        " categorical_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
        " categorical_cols = [c for c in categorical_cols if c != target]\n",
        " numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        " numeric_cols = [c for c in numeric_cols if c != target]\n",
        " print(\"Numeric Features:\", numeric_cols)\n",
        " print(\"Categorical Features:\", categorical_cols)\n",
        " # ------------------------\n",
        "# Train/Test Split\n",
        " # ------------------------\n",
        "X = df.drop(columns=[target])\n",
        " y = df[target]\n",
        " In [29]:\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.2, random_state=42, stratify=y\n",
        " )\n",
        " # ------------------------\n",
        "# Preprocessing Pipeline\n",
        " # ------------------------\n",
        "numeric_transformer = Pipeline(steps=[\n",
        " (\"scaler\", StandardScaler())\n",
        " ])\n",
        " categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
        " preprocessor = ColumnTransformer(\n",
        " transformers=[\n",
        " (\"num\", numeric_transformer, numeric_cols),\n",
        " (\"cat\", categorical_transformer, categorical_cols),\n",
        " ]\n",
        " )\n",
        " # ------------------------\n",
        "# Model Pipeline\n",
        " # ------------------------\n",
        "clf = Pipeline(steps=[\n",
        " (\"preprocessor\", preprocessor),\n",
        " (\"model\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
        " ])\n",
        " clf.fit(X_train, y_train)\n",
        " y_pred = clf.predict(X_test)\n",
        " y_proba = clf.predict_proba(X_test)[:, 1]\n",
        " # ------------------------\n",
        "# Evaluation\n",
        " # ------------------------\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        " prec = precision_score(y_test, y_pred)\n",
        " rec = recall_score(y_test, y_pred)\n",
        " f1 = f1_score(y_test, y_pred)\n",
        " roc = roc_auc_score(y_test, y_proba)\n",
        " print(\"\\nEvaluation Metrics:\")\n",
        " print(f\"Accuracy: {acc:.4f}\")\n",
        " print(f\"Precision: {prec:.4f}\")\n",
        " print(f\"Recall: {rec:.4f}\")\n",
        " print(f\"F1-score: {f1:.4f}\")\n",
        " print(f\"ROC-AUC: {roc:.4f}\")\n",
        " print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        " # ------------------------\n",
        "# SHAP Analysis\n",
        " # ------------------------\n",
        "# Extract trained RF and transformed data\n",
        " rf_model = clf.named_steps[\"model\"]\n",
        "X_train_transformed = clf.named_steps[\"preprocessor\"].transform(X_train)\n",
        " X_test_transformed = clf.named_steps[\"preprocessor\"].transform(X_test)\n",
        " # Get feature names from ColumnTransformer\n",
        " ohe = clf.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
        " ohe_features = ohe.get_feature_names_out(categorical_cols)\n",
        " all_features = numeric_cols + list(ohe_features)\n",
        " # Convert transformed arrays to DataFrames\n",
        " X_train_df = pd.DataFrame(\n",
        " X_train_transformed.toarray() if hasattr(X_train_transformed, \"toarray\") else\n",
        " columns=all_features\n",
        " )\n",
        " X_test_df = pd.DataFrame(\n",
        " X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else\n",
        " columns=all_features\n",
        " )\n",
        " # ------------------------\n",
        "# SHAP Analysis (fixed)\n",
        " # ------------------------\n",
        "# Build explainer with background = train set\n",
        " explainer = shap.Explainer(rf_model, X_train_df)\n",
        " # Get SHAP values (disable additivity check to avoid floating errors)\n",
        " shap_values = explainer(X_test_df, check_additivity=False)\n",
        " # ------------------------\n",
        "# Global explanation\n",
        " # ------------------------\n",
        "shap.summary_plot(shap_values, X_test_df, plot_type=\"bar\")\n",
        " shap.summary_plot(shap_values, X_test_df)"
      ],
      "metadata": {
        "id": "SwYgsS0IPoQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}